# -*- coding: utf-8 -*-
"""Proyecto_Final_2023_Harold.ipynb

Automatically generated by Colaboratory.

**Elaborado por:**

+ Harold H Hernandez

_____________________________________________________________
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np # linear algebra
import pandas as pd # data processing
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
ecomm = pd.read_csv("/content/ecomm.csv")

"""#**Entendimiento de los datos**

**1.1 Entendimiento de Negocio

El objetivo principal podría ser lograr una tasa de precisión de al menos el 80 % en la predicción de las calificaciones de los clientes dentro de un año utilizando detalles de pedidos específicos. Esto ayudará a las empresas a tomar decisiones basadas en datos sobre sus productos, estrategias de marketing y servicio al cliente. Las preguntas comerciales relacionadas son

1.  ¿Se está respondiendo la consulta del cliente?

2. ¿Se entregó el producto a tiempo?

3. ¿la importancia del producto es alta?


Para que nuestro objetivo se convierta en realidad, necesitamos un plan de proyecto que describa los pasos necesarios, las limitaciones (por ejemplo, el tamaño del conjunto de datos que se puede utilizar para el modelado), la fecha límite, los riesgos/eventos que podrían causar retrasos o fallas en el proceso. del proyecto, así como los correspondientes planes de contingencia.**

Contenido

El conjunto de datos utilizado para la construcción del modelo contenía 10999 observaciones de 12 variables.
Los datos contienen la siguiente información:

- ID: Número de identificación de los Clientes.
-  Bloque de almacén: la empresa tiene un gran almacén que se divide en bloques como A, B, C, D, F.
- Modo de envío: La empresa envía los productos de múltiples formas, como barco, vuelo y carretera.
- Llamadas de atención al cliente: Número de llamadas realizadas desde consulta para consulta del envío.
- Calificación del cliente: La empresa ha calificado a cada cliente. 1 es el más bajo (peor), 5 es el más alto (mejor).
- Costo del Producto: Costo del Producto en Dólares Estadounidenses.
- Compras Anteriores: El Número de Compra Anterior.
- Importancia del producto: La empresa ha categorizado el producto en diversos parámetros, como bajo, medio y alto.
- Género: Masculino y Femenino.
- Descuento ofrecido: Descuento ofrecido en ese producto específico.
- Peso en gms: Es el peso en gramos.
- Llegado a tiempo: Es la variable objetivo, donde 1 Indica que el producto NO ha llegado a tiempo y 0 indica que ha llegado a tiempo.

**1.2 Identificamos las columnas (variables) que componen el dataset y el tipo de dato que contiene cada una de ellas. Podemos observar que todas las variables son númericas y una de ella es de tipo entero, las demás poseen valores flotantes.**
"""

ecomm.info()

"""**2. Cambio formato nombres para que queden como titulos y busqueda de valores nulos**"""

new_cols=[]
for i in ecomm.columns[1:-1]:
    i = i.replace("_"," ")
    i = i.title()
    new_cols.append(i);
new_cols = ['ID'] +  new_cols
new_cols.append('Arrival')
ecomm.columns = new_cols
ecomm.columns.to_list()

ecomm.isnull().sum().sum()

"""**3. Estadísticas descriptivas del dataset**"""

ecomm.iloc[:,1:-1].describe()

ecomm.describe(include='object')

# Plotting multiple graphs in a grid
# Exploring the distribution of numeric columns using cumulative frequency distribution
fig, ax = plt.subplots(figsize=(20,16), facecolor='#F2F4F4')
fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.2, hspace=0.5)
count=1
ls = ['Cost Of The Product', 'Weight In Gms', 'Discount Offered']
for i in ls:
    plt.subplot(3,1,count)
    h = sns.histplot(x=i, kde=True, data=ecomm)
    h.set_title(('frequency distribution of ' + i).title(), fontsize=13)
    count+=1

# for categorical data
fig, axes = plt.subplots(4,2,figsize=(16,25), facecolor='#F2F4F4')

# countplot for 'Warehouse Block'
abs_whs=ecomm["Warehouse Block"].value_counts(ascending=False)
sns.countplot(x=ecomm["Warehouse Block"], order=abs_whs.index, ax=axes[0,0], palette='CMRmap_r')
axes[0,0].set_title('Orders Handled By Each Warehouse Block', fontsize=12)
rel_whs=ecomm["Warehouse Block"].value_counts(ascending=False, normalize=True).values*100
lbs_whs=[f"{w[0]} ({w[1]:.2f}%)" for w in zip(abs_whs,rel_whs)]
axes[0,0].bar_label(container=axes[0,0].containers[0], labels=lbs_whs)

# countplot for 'Mode Of Shipment'
abs_ship = ecomm["Mode Of Shipment"].value_counts(ascending=False)
sns.countplot(x=ecomm["Mode Of Shipment"], order=abs_ship.index, ax=axes[0,1], palette=['#DC143C','#556b2f','#008b8b'])
axes[0,1].set_title('Number of Orders By Shipment Mode', fontsize=12)
rel_ship = ecomm["Mode Of Shipment"].value_counts(ascending=False, normalize=True).values*100
lbs_ship = [f"{s[0]} ({s[1]:.2f}%)" for s in zip (abs_ship,rel_ship)]
axes[0,1].bar_label(container=axes[0,1].containers[0], labels=lbs_ship)

# countplot for 'Customer Care Calls'
abs_calls=ecomm["Customer Care Calls"].value_counts(ascending=False)
sns.countplot(x=ecomm["Customer Care Calls"], order=abs_calls.index,ax=axes[1,0],palette='cubehelix')
axes[1,0].set_title('Number of Customer Care Calls Made by Customers', fontsize=12)
rel_calls=ecomm["Customer Care Calls"].value_counts(ascending=False, normalize=True).values*100
lbs_calls=[f"{c[0]} ({c[1]:.2f}%)" for c in zip(abs_calls, rel_calls)]
axes[1,0].bar_label(container=axes[1,0].containers[0], labels=lbs_calls)

# countplot for 'Customer Rating'
abs_rating = ecomm["Customer Rating"].value_counts(ascending=False)
sns.countplot(x=ecomm["Customer Rating"], order=abs_rating.index,ax=axes[1,1],palette="rocket")
axes[1,1].set_title('Customer Rating Received', fontsize=12);
rel_rating = ecomm["Customer Rating"].value_counts(ascending=False, normalize=True).values*100
lbs_rating = [f"{r[0]} ({r[1]:.2f}%)" for r in zip(abs_rating, rel_rating)]
axes[1,1].bar_label(container=axes[1,1].containers[0], labels=lbs_rating)

# countplot for 'Prior Purchases'
abs_prior_pur = ecomm["Prior Purchases"].value_counts(ascending=False)
sns.countplot(x=ecomm["Prior Purchases"], order=abs_prior_pur.index,ax=axes[2,0],palette='viridis')
axes[2,0].set_title('Number of Prior Purchases Made by Customers', fontsize=12)
rel_prior_pur = ecomm["Prior Purchases"].value_counts(ascending=False, normalize=True).values*100
lbs_prior_pur = [f"{pur[0]} ({pur[1]:.0f}%)" for pur in zip(abs_prior_pur, rel_prior_pur)]
axes[2,0].bar_label(container=axes[2,0].containers[0], labels=lbs_prior_pur)

# countplot for 'Product Importance'
abs_priority = ecomm["Product Importance"].value_counts(ascending=False)
sns.countplot(x=ecomm["Product Importance"], order=abs_priority.index,ax=axes[2,1])
axes[2,1].set_title('Number of Orders Made by Product Importance', fontsize=12)
rel_priority = ecomm["Product Importance"].value_counts(ascending=False, normalize=True).values*100
lbs_priority = [f"{i[0]} ({i[1]:.2f}%)" for i in zip(abs_priority, rel_priority)]
axes[2,1].bar_label(container=axes[2,1].containers[0], labels=lbs_priority)

# countplot for 'Gender'
abs_gender = ecomm["Gender"].value_counts(ascending=False)
sns.countplot(x=ecomm["Gender"], order=abs_gender.index,ax=axes[3,0],palette=['#800000','#191970'])
axes[3,0].set_title("Number of Orders Made by Customers' Gender", fontsize=12)
rel_gender = ecomm["Gender"].value_counts(ascending=False, normalize=True).values*100
lbs_gender = [f"{g[0]} ({g[1]:.2f}%)" for g in zip(abs_gender, rel_gender)]
axes[3,0].bar_label(container=axes[3,0].containers[0], labels=lbs_gender)

# countplot for 'Arrival'
abs_arrival = ecomm["Arrival"].value_counts(ascending=False)
sns.countplot(x=ecomm["Arrival"], order=abs_arrival.index,ax=axes[3,1],palette='tab20c_r')
axes[3,1].set_title('Number of Orders Based On Arrival Time', fontsize=12)
axes[3,1].set_xticklabels(['Late', 'On Time'])
rel_arrival = ecomm["Arrival"].value_counts(ascending=False, normalize=True).values*100
lbls_arrival=[f"{a[0]}({a[1]:.2f}%)" for a in zip(abs_arrival,rel_arrival)]
axes[3,1].bar_label(container=axes[3,1].containers[0],labels=lbls_arrival);

# librerias para modelos
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier as DT


# crear variables ficticias para variables categóricas
ecomm['Gender'] = ecomm.Gender.map({'F':0, 'M':1})
ecomm['Customer Rating'] = ecomm['Customer Rating'].map({5:0, 4:0, 3:0, 2:0, 1:1})
dummy = pd.DataFrame(pd.get_dummies(ecomm[['Warehouse Block', 'Mode Of Shipment','Product Importance']]))

# para normalizar datos
from sklearn.preprocessing import scale
ecomm1 = pd.DataFrame(scale(ecomm[['Cost Of The Product','Discount Offered', 'Weight In Gms']]), columns=['Cost Of the Product','Discount Offered', 'Weight In Gms'])

# creaar nuevo datafame para modelado
ecomm_final = pd.concat([ecomm1, dummy,ecomm[['Customer Care Calls', 'Prior Purchases','Gender', 'Arrival','Customer Rating']]],
                        axis=1)

# Dividir datos en salida y entrada
X = ecomm_final.iloc[:,:-1] # inputs
Y = ecomm_final['Customer Rating'] # outputs

# vidividir data en train data and test data
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.25,shuffle=True)

# agregar diferentes modelos de clasificación en una matriz de clasificadores
classifiers=[]
KNN_model = KNeighborsClassifier(n_neighbors=11, metric='euclidean')
classifiers.append(KNN_model)
DT_model = DT(criterion = 'entropy',max_depth=4)
classifiers.append(DT_model)

from sklearn.metrics import accuracy_score
accuracy_train = []
accuracy_test = []
for clf in classifiers:
    clf.fit(X_train, Y_train)
    pred_train = clf.predict(X_train)
    pred_test = clf.predict(X_test)
    acc_train = accuracy_score(Y_train, pred_train)
    acc_test = accuracy_score(Y_test, pred_test)
    accuracy_train.append(acc_train)
    accuracy_test.append(acc_test)
accuracy_result = pd.DataFrame(data={'Model':['KNN','Decision Tree'],
                                     'Training Accuracy':accuracy_train,
                                     'Testing Accuracy':accuracy_test})
accuracy_result.sort_values('Testing Accuracy',ascending=False)

import pickle

# Save the trained model using pickle
model_filename = 'Knn_model.pkl'
with open(model_filename, 'wb') as model_file:
    pickle.dump(KNN_model, model_file)
print(f"Model saved as {model_filename}")